{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage, spatial\n",
    "\n",
    "import transformations\n",
    "\n",
    "\n",
    "def inbounds(shape, indices):\n",
    "    assert len(shape) == len(indices)\n",
    "    for i, ind in enumerate(indices):\n",
    "        if ind < 0 or ind >= shape[i]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointDetector(object):\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- uint8 BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class DummyKeypointDetector(KeypointDetector):\n",
    "    '''\n",
    "    Compute silly example features. This doesn't do anything meaningful, but\n",
    "    may be useful to use as an example.\n",
    "    '''\n",
    "\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- uint8 BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        features = []\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                r = image[y, x, 0]\n",
    "                g = image[y, x, 1]\n",
    "                b = image[y, x, 2]\n",
    "\n",
    "                if int(255 * (r + g + b) + 0.5) % 100 == 1:\n",
    "                    # If the pixel satisfies this meaningless criterion,\n",
    "                    # make it a feature.\n",
    "\n",
    "                    f = cv2.KeyPoint()\n",
    "                    f.pt = (x, y)\n",
    "                    # Dummy size\n",
    "                    f.size = 10\n",
    "                    f.angle = 0\n",
    "                    f.response = 10\n",
    "\n",
    "                    features.append(f)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class HarrisKeypointDetector(KeypointDetector):\n",
    "\n",
    "    # Compute harris values of an image.\n",
    "    def computeHarrisValues(self, srcImage):\n",
    "        '''\n",
    "        Input:\n",
    "            srcImage -- Grayscale input image in a numpy array with\n",
    "                        values in [0, 1]. The dimensions are (rows, cols).\n",
    "        Output:\n",
    "            harrisImage -- numpy array containing the Harris score at\n",
    "                           each pixel.\n",
    "            orientationImage -- numpy array containing the orientation of the\n",
    "                                gradient at each pixel in degrees.\n",
    "        '''\n",
    "        height, width = srcImage.shape[:2]\n",
    "\n",
    "        harrisImage = np.zeros(srcImage.shape[:2])\n",
    "        orientationImage = np.zeros(srcImage.shape[:2])\n",
    "\n",
    "        # TODO 1: Compute the harris corner strength for 'srcImage' at\n",
    "        # each pixel and store in 'harrisImage'.  See the project page\n",
    "        # for direction on how to do this. Also compute an orientation\n",
    "        # for each pixel and store it in 'orientationImage.'\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        \n",
    "        # Compute the x, y derivatives\n",
    "        i_x = ndimage.sobel(srcImage, 1)\n",
    "        i_y = ndimage.sobel(srcImage, 0)\n",
    "        \n",
    "        i_xx = i_x ** 2\n",
    "        i_yy = i_y ** 2\n",
    "        i_xy = i_x * i_y\n",
    "        \n",
    "        # Gauss mask\n",
    "        gauss_xx = ndimage.gaussian_filter(i_xx, 0.5)\n",
    "        gauss_yy = ndimage.gaussian_filter(i_yy, 0.5)\n",
    "        gauss_xy = ndimage.gaussian_filter(i_xy, 0.5)\n",
    "        \n",
    "        for x in range(height):\n",
    "            for y in range(width):\n",
    "                H = np.array([[gauss_xx[x, y], gauss_xy[x, y]], [gauss_xy[x, y], gauss_yy[x, y]]], dtype = \"float\")\n",
    "                harrisImage[x, y] = np.linalg.det(H) - 0.1 * np.trace(H) ** 2\n",
    "                orientationImage[x, y] = np.degrees(np.arctan2(i_y[x, y], i_x[x, y]))\n",
    "        # TODO-BLOCK-END\n",
    "\n",
    "        return harrisImage, orientationImage\n",
    "\n",
    "    def computeLocalMaxima(self, harrisImage):\n",
    "        '''\n",
    "        Input:\n",
    "            harrisImage -- numpy array containing the Harris score at\n",
    "                           each pixel.\n",
    "        Output:\n",
    "            destImage -- numpy array containing True/False at\n",
    "                         each pixel, depending on whether\n",
    "                         the pixel value is the local maxima in\n",
    "                         its 7x7 neighborhood.\n",
    "        '''\n",
    "        #destImage = np.zeros_like(harrisImage, np.bool)\n",
    "\n",
    "        # TODO 2: Compute the local maxima image\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        maxima = ndimage.filters.maximum_filter(harrisImage, (7, 7))\n",
    "        destImage = maxima - harrisImage\n",
    "        # TODO-BLOCK-END\n",
    "\n",
    "        return destImage == 0\n",
    "\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        height, width = image.shape[:2]\n",
    "        features = []\n",
    "\n",
    "        # Create grayscale image used for Harris detection\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # computeHarrisValues() computes the harris score at each pixel\n",
    "        # position, storing the result in harrisImage.\n",
    "        # You will need to implement this function.\n",
    "        harrisImage, orientationImage = self.computeHarrisValues(grayImage)\n",
    "\n",
    "        # Compute local maxima in the Harris image.  You will need to\n",
    "        # implement this function. Create image to store local maximum harris\n",
    "        # values as True, other pixels False\n",
    "        harrisMaxImage = self.computeLocalMaxima(harrisImage)\n",
    "\n",
    "        # Loop through feature points in harrisMaxImage and fill in information\n",
    "        # needed for descriptor computation for each point.\n",
    "        # You need to fill x, y, and angle.\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                if not harrisMaxImage[y, x]:\n",
    "                    continue\n",
    "\n",
    "                f = cv2.KeyPoint()\n",
    "\n",
    "                # TODO 3: Fill in feature f with location and orientation\n",
    "                # data here. Set f.size to 10, f.pt to the (x,y) coordinate,\n",
    "                # f.angle to the orientation in degrees and f.response to\n",
    "                # the Harris score\n",
    "                # TODO-BLOCK-BEGIN\n",
    "                f.size = 10\n",
    "                f.pt = (x, y)\n",
    "                f.angle = orientationImage[y, x]\n",
    "                f.response = harrisImage[y, x]\n",
    "                # TODO-BLOCK-END\n",
    "\n",
    "                features.append(f)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_rot_mx(angle_x, angle_y, angle_z):\n",
    "    '''\n",
    "    Input:\n",
    "        angle_x -- Rotation around the x axis in radians\n",
    "        angle_y -- Rotation around the y axis in radians\n",
    "        angle_z -- Rotation around the z axis in radians\n",
    "    Output:\n",
    "        A 4x4 numpy array representing 3D rotations. The order of the rotation\n",
    "        axes from first to last is x, y, z, if you multiply with the resulting\n",
    "        rotation matrix from left.\n",
    "    '''\n",
    "    # Note: For MOPS, you need to use angle_z only, since we are in 2D\n",
    "\n",
    "    rot_x_mx = np.array([[1, 0, 0, 0],\n",
    "                         [0, math.cos(angle_x), -math.sin(angle_x), 0],\n",
    "                         [0, math.sin(angle_x), math.cos(angle_x), 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "\n",
    "    rot_y_mx = np.array([[math.cos(angle_y), 0, math.sin(angle_y), 0],\n",
    "                         [0, 1, 0, 0],\n",
    "                         [-math.sin(angle_y), 0, math.cos(angle_y), 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "\n",
    "    rot_z_mx = np.array([[math.cos(angle_z), -math.sin(angle_z), 0, 0],\n",
    "                         [math.sin(angle_z), math.cos(angle_z), 0, 0],\n",
    "                         [0, 0, 1, 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "\n",
    "    return np.dot(rot_z_mx, np.dot(rot_y_mx, rot_x_mx))\n",
    "\n",
    "\n",
    "def get_trans_mx(trans_vec):\n",
    "    '''\n",
    "    Input:\n",
    "        trans_vec -- Translation vector represented by an 1D numpy array with 3\n",
    "        elements\n",
    "    Output:\n",
    "        A 4x4 numpy array representing 3D translation.\n",
    "    '''\n",
    "    assert trans_vec.ndim == 1\n",
    "    assert trans_vec.shape[0] == 3\n",
    "\n",
    "    trans_mx = np.eye(4)\n",
    "    trans_mx[:3, 3] = trans_vec\n",
    "\n",
    "    return trans_mx\n",
    "\n",
    "\n",
    "def get_scale_mx(s_x, s_y, s_z):\n",
    "    '''\n",
    "    Input:\n",
    "        s_x -- Scaling along the x axis\n",
    "        s_y -- Scaling along the y axis\n",
    "        s_z -- Scaling along the z axis\n",
    "    Output:\n",
    "        A 4x4 numpy array representing 3D scaling.\n",
    "    '''\n",
    "    # Note: For MOPS, you need to use s_x and s_y only, since we are in 2D\n",
    "    scale_mx = np.eye(4)\n",
    "\n",
    "    for i, s in enumerate([s_x, s_y, s_z]):\n",
    "        scale_mx[i, i] = s\n",
    "\n",
    "    return scale_mx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDescriptor(object):\n",
    "    # Implement in child classes\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            Descriptor numpy array, dimensions:\n",
    "                keypoint number x feature descriptor dimension\n",
    "        '''\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOPSFeatureDescriptor(FeatureDescriptor):\n",
    "    # TODO: Implement parts of this function\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            desc -- K x W^2 numpy array, where K is the number of keypoints\n",
    "                    and W is the window size\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        # This image represents the window around the feature you need to\n",
    "        # compute to store as the feature descriptor (row-major)\n",
    "        windowSize = 8\n",
    "        desc = np.zeros((len(keypoints), windowSize * windowSize))\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        grayImage = ndimage.gaussian_filter(grayImage, 0.5)\n",
    "        for i, f in enumerate(keypoints):\n",
    "            # TODO 5: Compute the transform as described by the feature\n",
    "            # location/orientation. You will need to compute the transform\n",
    "            # from each pixel in the 40x40 rotated window surrounding\n",
    "            # the feature to the appropriate pixels in the 8x8 feature\n",
    "            # descriptor image.\n",
    "            transMx = np.zeros((2, 3))\n",
    "\n",
    "            # TODO-BLOCK-BEGIN\n",
    "            # Get axis\n",
    "            x, y = f.pt\n",
    "            temp_pt = np.array([-x, -y, 0])\n",
    "            # Get response\n",
    "            respon = f.response\n",
    "            # Get angle back in rad\n",
    "            rad_angle = np.deg2rad(f.angle)\n",
    "            # Get rotation: For MOPS, you need to use angle_z only, since we are in 2D\n",
    "            rotations = get_rot_mx(0, 0, -rad_angle)[:,[0, 1, 3]][[0, 1, 3], :]\n",
    "            # Get translation matrix\n",
    "            trans = get_trans_mx(temp_pt)[:,[0, 1, 3]][[0, 1, 3], :]\n",
    "            # Get scale down by 5\n",
    "            scales = get_scale_mx(1/5, 1/5, 0)[:,[0, 1, 3]][[0, 1, 3], :]\n",
    "            # translation 2 to match axis\n",
    "            trans_2 = get_trans_mx(np.array([4,4,0]))[:, [0, 1, 3]][[0, 1, 3], :]\n",
    "            # Dot them\n",
    "            dot_tran = trans_2.dot(scales).dot(rotations).dot(trans)\n",
    "            transMx = dot_tran[:2,:]\n",
    "\n",
    "            # TODO-BLOCK-END\n",
    "\n",
    "            # Call the warp affine function to do the mapping\n",
    "            # It expects a 2x3 matrix\n",
    "            destImage = cv2.warpAffine(grayImage, transMx,\n",
    "                (windowSize, windowSize), flags=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # TODO 6: Normalize the descriptor to have zero mean and unit \n",
    "            # variance. If the variance is negligibly small (which we \n",
    "            # define as less than 1e-10) then set the descriptor\n",
    "            # vector to zero. Lastly, write the vector to desc.\n",
    "            # TODO-BLOCK-BEGIN\n",
    "            image_mean = np.mean(destImage)\n",
    "            image_std = np.std(destImage)\n",
    "            if image_std ** 2 > 1e-10:\n",
    "                desc[i] = ((np.array(destImage) - image_mean) / image_std).flatten()\n",
    "            else:\n",
    "                desc[i] = np.zeros(windowSize * windowSize)\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MOPSFeatureDescriptor()\n",
    "what0 = p.describeFeatures(image_0, ff0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMatcher(object):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        '''\n",
    "        Input:\n",
    "            desc1 -- the feature descriptors of image 1 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "            desc2 -- the feature descriptors of image 2 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "        Output:\n",
    "            features matches: a list of cv2.DMatch objects\n",
    "                How to set attributes:\n",
    "                    queryIdx: The index of the feature in the first image\n",
    "                    trainIdx: The index of the feature in the second image\n",
    "                    distance: The distance between the two features\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Evaluate a match using a ground truth homography.  This computes the\n",
    "    # average SSD distance between the matched feature points and\n",
    "    # the actual transformed positions.\n",
    "    @staticmethod\n",
    "    def evaluateMatch(features1, features2, matches, h):\n",
    "        d = 0\n",
    "        n = 0\n",
    "\n",
    "        for m in matches:\n",
    "            id1 = m.queryIdx\n",
    "            id2 = m.trainIdx\n",
    "            ptOld = np.array(features2[id2].pt)\n",
    "            ptNew = FeatureMatcher.applyHomography(features1[id1].pt, h)\n",
    "\n",
    "            # Euclidean distance\n",
    "            d += np.linalg.norm(ptNew - ptOld)\n",
    "            n += 1\n",
    "\n",
    "        return d / n if n != 0 else 0\n",
    "\n",
    "    # Transform point by homography.\n",
    "    @staticmethod\n",
    "    def applyHomography(pt, h):\n",
    "        x, y = pt\n",
    "        d = h[6]*x + h[7]*y + h[8]\n",
    "\n",
    "        return np.array([(h[0]*x + h[1]*y + h[2]) / d,\n",
    "            (h[3]*x + h[4]*y + h[5]) / d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatioFeatureMatcher(FeatureMatcher):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        '''\n",
    "        Input:\n",
    "            desc1 -- the feature descriptors of image 1 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "            desc2 -- the feature descriptors of image 2 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "        Output:\n",
    "            features matches: a list of cv2.DMatch objects\n",
    "                How to set attributes:\n",
    "                    queryIdx: The index of the feature in the first image\n",
    "                    trainIdx: The index of the feature in the second image\n",
    "                    distance: The ratio test score\n",
    "        '''\n",
    "        matches = []\n",
    "        # feature count = n\n",
    "        assert desc1.ndim == 2\n",
    "        # feature count = m\n",
    "        assert desc2.ndim == 2\n",
    "        # the two features should have the type\n",
    "        assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "        if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "            return []\n",
    "\n",
    "        # TODO 8: Perform ratio feature matching.\n",
    "        # This uses the ratio of the SSD distance of the two best matches\n",
    "        # and matches a feature in the first image with the closest feature in the\n",
    "        # second image.\n",
    "        # Note: multiple features from the first image may match the same\n",
    "        # feature in the second image.\n",
    "        # You don't need to threshold matches in this function\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        \n",
    "        # Check every feature in first image\n",
    "        for i in range(desc1.shape[0]):\n",
    "            # Take one feature from the first image\n",
    "            first_part = [desc1[i]]\n",
    "            # Calculate distance from all features in second image\n",
    "            dist = scipy.spatial.distance.cdist(first_part, desc2)[0]\n",
    "            # Sort\n",
    "            sorted_dist = np.argsort(dist)\n",
    "            # Find the index of the closest and second closest feature\n",
    "            min_1 = sorted_dist[0]\n",
    "            min_2 = sorted_dist[1]\n",
    "            # Calculate the ratio\n",
    "            if dist[min_1] == 0 and dist[min_2] == 0:\n",
    "                r = 0\n",
    "            else:\n",
    "                r = dist[min_1] / dist[min_2]\n",
    "            matches.append(cv2.DMatch(i, min_1, r))\n",
    "        # TODO-BLOCK-END\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_0 = cv2.imread(\"resources/triangle1.jpg\")\n",
    "image_0 = cv2.cvtColor(image_0, cv2.COLOR_BGR2RGB)\n",
    "image_1 = cv2.imread(\"resources/triangle2.jpg\")\n",
    "image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = HarrisKeypointDetector()\n",
    "ff0 = c.detectKeypoints(image_0)\n",
    "ff1 = c.detectKeypoints(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MOPSFeatureDescriptor()\n",
    "what0 = p.describeFeatures(image_0, ff0)\n",
    "what1 = p.describeFeatures(image_1, ff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RatioFeatureMatcher()\n",
    "res = m.matchFeatures(what0, what1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
